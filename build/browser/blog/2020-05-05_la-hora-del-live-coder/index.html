<html><head><meta charset="utf-8" /><link href="/images/favicon/apple-touch-icon-57x57.png" rel="apple-touch-icon-precomposed" sizes="57x57" /><link href="/images/favicon/apple-touch-icon-114x114.png" rel="apple-touch-icon-precomposed" sizes="114x114" /><link href="/images/favicon/apple-touch-icon-72x72.png" rel="apple-touch-icon-precomposed" sizes="72x72" /><link href="/images/favicon/apple-touch-icon-144x144.png" rel="apple-touch-icon-precomposed" sizes="144x144" /><link href="/images/favicon/apple-touch-icon-60x60.png" rel="apple-touch-icon-precomposed" sizes="60x60" /><link href="/images/favicon/apple-touch-icon-120x120.png" rel="apple-touch-icon-precomposed" sizes="120x120" /><link href="/images/favicon/apple-touch-icon-76x76.png" rel="apple-touch-icon-precomposed" sizes="76x76" /><link href="/images/favicon/apple-touch-icon-152x152.png" rel="apple-touch-icon-precomposed" sizes="152x152" /><link href="/images/favicon/favicon-196x196.png" rel="icon" sizes="196x196" type="image/png" /><link href="/images/favicon/favicon-96x96.png" rel="icon" sizes="96x96" type="image/png" /><link href="/images/favicon/favicon-32x32.png" rel="icon" sizes="32x32" type="image/png" /><link href="/images/favicon/favicon-16x16.png" rel="icon" sizes="16x16" type="image/png" /><link href="/images/favicon/favicon-128.png" rel="icon" sizes="128x128" type="image/png" /><link href="/css/mazorca.css" rel="stylesheet" type="text/css" /><link crossorigin="anonymous" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" /><meta content=" " name="application-name" /><meta content="width=device-width, initial-scale=1" name="viewport" /><meta content="#FFFFFF" name="msapplication-TileColor" /><meta content="mstile-144x144.png" name="msapplication-TileImage" /><meta content="mstile-70x70.png" name="msapplication-square70x70logo" /><meta content="mstile-150x150.png" name="msapplication-square150x150logo" /><meta content="mstile-310x150.png" name="msapplication-wide310x150logo" /><meta content="mstile-310x310.png" name="msapplication-square310x310logo" /><meta content="Diego Villaseñor" name="application-name" /><meta content="#FFFFFF" name="msapplication-TileColor" /><meta content="baseUrl+/images/favicon/mstile-144x144.png" name="msapplication-TileImage" /><meta content="baseUrl+/images/favicon/mstile-70x70.png" name="msapplication-square70x70logo" /><meta content="baseUrl+/images/favicon/mstile-150x150.png" name="msapplication-square150x150logo" /><meta content="baseUrl+/images/favicon/mstile-310x150.png" name="msapplication-wide310x150logo" /><meta content="baseUrl+/images/favicon/mstile-310x310.png" name="msapplication-square310x310logo" /><title>Diego Villaseñor | La hora del live coder</title><meta content="Performance for TopLap Barcelona. Using FluentCan and hydra to generate music and visual canons." name="description" /><meta content="summary_large_image" name="twitter:card" /><meta content="@diegovideco" name="twitter:site" /><meta content="@diegovideco" name="twitter:creator" /><meta content="Diego Villaseñor | La hora del live coder" name="twitter:title" /><meta content="Performance for TopLap Barcelona. Using FluentCan and hydra to generate music and visual canons." name="twitter:description" /><meta content="la-hora-del-live-coder.jpg" name="twitter:image" /><meta content="https://echoic.space/blog/2020-05-05_la-hora-del-live-coder" property="og:url" /><meta content="article" property="og:type" /><meta content="Diego Villaseñor | La hora del live coder" property="og:title" /><meta content="Performance for TopLap Barcelona. Using FluentCan and hydra to generate music and visual canons." property="og:description" /><meta content="la-hora-del-live-coder.jpg" property="og:image" /><meta content="3840" property="og:image:width" /><meta content="2160" property="og:image:height" /></head><body><div id="app"><header><nav class="menu-main"><div class="menu-main__container"><a class="menu-main__link" href="/" key="/">~/</a><a class="menu-main__link" href="/music/" key="/music/">~/música</a><a class="menu-main__link" href="/blog/" key="/blog/">~/bitácora</a><a class="menu-main__link" href="/about/" key="/about/">~/acerca</a><a class="menu-main__link" href="/contact/" key="/contact/">~/contacto</a></div></nav></header><div data-reactid=".0"><div data-reactid=".0.0"><div class="" data-reactid=".0.0.0"><div class="single__img--main" data-reactid=".0.0.0.0" style="background-image:url(/blog/2020-05-05_la-hora-del-live-coder/la-hora-del-live-coder.jpg);"><div data-reactid=".0.0.0.0.0"><div class="single__ttl-container" data-reactid=".0.0.0.0.0.0"><h1 class="single__ttl single__ttl--with-img" data-reactid=".0.0.0.0.0.0.0" id="single-ttl" style="fontSizes:200px;background-image:url(/blog/2020-05-05_la-hora-del-live-coder/la-hora-del-live-coder.jpg);">La hora del live coder</h1></div><span class="single__play fa fa-play" data-reactid=".0.0.0.0.0.1" style="background-image:url(/[object Object]/2020-05-05_la-hora-del-live-coder/la-hora-del-live-coder.jpg);"></span><span data-reactid=".0.0.0.0.0.2"></span></div></div><div class="single__video-player-container" data-reactid=".0.0.0.1" id="single__video-player-container"><div data-reactid=".0.0.0.1.0" id="player"><iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="allowfullscreen" data-reactid=".0.0.0.1.0.0" frameborder="0" height="315" src="https://www.youtube.com/embed/S-Y4cWhUE5I" title="YouTube video player" width="560"></iframe></div></div></div><div class="page single__bg-img single--2020-05-05_la-hora-del-live-coder" data-reactid=".0.0.1"><div class="grid__container single__bg-img single--2020-05-05_la-hora-del-live-coder__main-container" data-reactid=".0.0.1.0"><div class="grid__col-1-1" data-reactid=".0.0.1.0.0"><div data-reactid=".0.0.1.0.0.0"><div class="markdown-body" dangerouslySetInnerHTML="{:__html &quot;&lt;p&gt;&lt;em&gt;La hora del live coder&lt;/em&gt; is performance that explores possible strategies for visualizing temporal canons using &lt;a href=\&quot;https://github.com/nanc-in-a-can/fluent-can\&quot;&gt;FluentCan&lt;/a&gt; and &lt;a href=\&quot;https://hydra.ojack.xyz/\&quot;&gt;hydra&lt;/a&gt;. Additionally &lt;code&gt;Eikosanies&lt;/code&gt; were used as the music&amp;#39;s tuning system. The following is a tutorial for anyone interested in these techniques.&lt;/p&gt;\n&lt;p&gt;Personally, the most interesting thing about performance is in the communication between &lt;code&gt;supercollider&lt;/code&gt; and &lt;code&gt;hydra&lt;/code&gt;, since it is possible to control and even compile the &lt;code&gt;hydra&lt;/code&gt; code from &lt;code&gt;supercollider&lt;/code&gt;.&lt;/p&gt;\n&lt;p&gt;The second most interesting thing is that using &lt;code&gt;FluentCan&lt;/code&gt; in conjunction with &lt;code&gt;hydra&lt;/code&gt; (in this case) one can create graphical temporal canons, which is something I have not yet seen anywhere else.&lt;/p&gt;\n&lt;p&gt;The code repository and this tutorial can be found here: &lt;a href=\&quot;https://github.com/diegovdc/la-hora-del-live-coder\&quot;&gt;https://github.com/diegovdc/la-hora-del-live-coder&lt;/a&gt;&lt;/p&gt;\n&lt;h2 id=\&quot;how-to-compile-hydra-code-from-supercollider\&quot;&gt;How to compile hydra code from supercollider&lt;/h2&gt;\n&lt;p&gt;Please note that although this technique is used for compiling visual canons in &lt;code&gt;hydra&lt;/code&gt;, it can be adapted to any situation where the control of what and how gets compiled by &lt;code&gt;hydra&lt;/code&gt; should be defined by an external program.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;En Hydra&lt;/strong&gt;:&lt;/p&gt;\n&lt;p&gt;The most basic (althought) trivial implementation looks like this (see below for a non trivial implementation)&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&quot;lang-js\&quot;&gt;// `main` is a function that gets compiled every time there is a `compile` osc event\nmain = (oscPayload) =&amp;gt; shape(oscPayload[0]).out();\n\n// each time a /compile message is sent, then the main function is compiled...\nmsg.on(&amp;quot;/compile&amp;quot;, (oscPayload) =&amp;gt; {\n  main(oscPayload);\n});\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;This implementation is trivial because we don&amp;#39;t need to recompile &lt;code&gt;hydra&lt;/code&gt; to pass a new value to the &lt;code&gt;shape&lt;/code&gt; function. We could simply do this and save a lot of CPU cycles:&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&quot;lang-js\&quot;&gt;shape(() =&amp;gt; numberOfSides).out();\n\nmsg.on(&amp;quot;/changeSides&amp;quot;, (oscPayload) =&amp;gt; {\n  numberOfSides = oscPayload[0];\n});\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;In the performance, however, &lt;code&gt;FluentCan&lt;/code&gt; would produce canons with a different number of voices each time, so I wanted to automatically change in &lt;code&gt;hydra&lt;/code&gt; the number of &lt;code&gt;shapes&lt;/code&gt; that were produce to match the number of voices of the canon.&lt;/p&gt;\n&lt;p&gt;So I did the following.&lt;/p&gt;\n&lt;p&gt;First a layering function was need. If we want three layers (or voices) at a given time, then we want the layer function to be able to do something like this (but dynamically):&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&quot;lang-js\&quot;&gt;shape().diff(shape()).diff(shape());\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;Using the JS library Ramda layer looks simply like this.&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&quot;lang-js\&quot;&gt;layer = R.invoker(1, &amp;quot;diff&amp;quot;);\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;But &lt;code&gt;layer&lt;/code&gt; could also be written like this in vanilla js:&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&quot;lang-js\&quot;&gt;layer = (newLayer, accumulatedLayers) =&amp;gt; accumulatedLayers.diff(newLayer);\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;An example use of layer is this:&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&quot;lang-js\&quot;&gt;layer1 = layer(shape(2), shape(1)); //shape(1).diff(shape(2))\nlayer2 = layer(shape(3), layer1); // shape(1).diff(shape(2)).diff(shape(3))\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;But we want to create more interesting layers so this next function (&lt;code&gt;makeLayer&lt;/code&gt;) is in charge of creating each layer (i.e. each &lt;code&gt;shape()&lt;/code&gt;). It receives the data from a single voice (actually just the key) to create each of the shapes individually.&lt;/p&gt;\n&lt;p&gt;The &lt;code&gt;voices&lt;/code&gt; object holds all the the different voices data (see below); and this stateful object will be used to access the current voice values on every iteration of the &lt;code&gt;hydra&lt;/code&gt; graphics loop.&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&quot;lang-js\&quot;&gt;// this version returns a colored shape, but it can be as complex as desired\nmakeLayer = (voice) =&amp;gt;\n  solid(\n    () =&amp;gt; voices[voice].r || 0,\n    () =&amp;gt; voices[voice].g || 0,\n    () =&amp;gt; voices[voice].b || 0\n  ).mask(shape(() =&amp;gt; voices[voice].shape || 3));\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;Next we define the &lt;code&gt;main&lt;/code&gt; function which gets recompiled via osc.&lt;/p&gt;\n&lt;p&gt;Here &lt;code&gt;R.reduce&lt;/code&gt; is used to iterate by the number of voices and &lt;em&gt;accumulate&lt;/em&gt; our layers into a single signal. (Using js native &lt;code&gt;.reduce&lt;/code&gt; or even &lt;code&gt;for loop&lt;/code&gt; are good also alternatives).&lt;/p&gt;\n&lt;p&gt;So if there are 2 voices one would get something like:&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&quot;lang-js\&quot;&gt;shape(1).diff(shape(2));\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;And with 3 voices something like:&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&quot;lang-js\&quot;&gt;shape(1).diff(shape(2)).diff(shape(3));\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;However for our function to work we need a &lt;em&gt;base&lt;/em&gt; layer. Something neutral, like &lt;code&gt;solid(0,0,0)&lt;/code&gt;, works well. So we are actually going to get something like this:&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&quot;lang-js\&quot;&gt;solid(0, 0, 0).diff(shape(1)).diff(shape(2)).diff(shape(3));\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;And so on... All generated automatically.&lt;/p&gt;\n&lt;p&gt;One would just need to substitute &lt;code&gt;shape&lt;/code&gt; by whatever the output of makeLayer is.&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&quot;lang-js\&quot;&gt;main = (voices) =&amp;gt;\n  R.reduce(\n    (acc, voice) =&amp;gt; layer(makeLayer(voice), acc), // voice is just a key in the voices object, i.e. `&amp;quot;v1&amp;quot;`, or `&amp;quot;v2&amp;quot;`\n    solid(0, 0, 0), // this is the initial or base layer\n    Object.keys(voices)\n  ).out(); // we call .out on the accumulated layers\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;The content of the &lt;code&gt;voices&lt;/code&gt; object is defined separately, so that when a voice&amp;#39;s parameter is updated (on every sound event), the object changes but the &lt;code&gt;hydra&lt;/code&gt; code need not be recompiled.&lt;/p&gt;\n&lt;p&gt;This object looks like this:&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&quot;lang-js\&quot;&gt;{\n  v1: {\n    voiceIndex: 1,\n    r: 0.5,\n    g: 1,\n    b: 0,\n    // more params\n  },\n  v2: {\n    voiceIndex: 2,\n    r: 0,\n    g: 0.1,\n    b: 0.7\n    // more params\n  },\n  // more voices\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;To update the voices object we use a message called &lt;code&gt;/canosc&lt;/code&gt;.&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&quot;lang-js\&quot;&gt;msg.on(&amp;quot;/canosc&amp;quot;, (msg_) =&amp;gt; {\n  // don&amp;#39;t mind this next line too much, it just parses the osc message into an object like: {voiceIndex: 1, r: 0.5, g: 1, b: 0, ...otherParams}\n  var msg__ = R.fromPairs(R.splitEvery(2, msg_));\n\n  // the parsed voice is assigned to the voices object which the looks like this:\n  // {v1: {r:0.5, ...otherParams}, v2: {...params}, ...}\n  voices[&amp;quot;v&amp;quot; + msg__.voiceIndex] = msg__;\n});\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;Resources in the actual code: &lt;a href=\&quot;https://github.com/diegovdc/la-hora-del-live-coder/blob/master/index.js#L14-L23\&quot;&gt;https://github.com/diegovdc/la-hora-del-live-coder/blob/master/index.js#L14-L23&lt;/a&gt; y &lt;a href=\&quot;https://github.com/diegovdc/la-hora-del-live-coder/blob/master/index.js#L41-L51\&quot;&gt;https://github.com/diegovdc/la-hora-del-live-coder/blob/master/index.js#L41-L51&lt;/a&gt;&lt;/p&gt;\n&lt;p&gt;For compiling &lt;code&gt;hydra&lt;/code&gt; the &lt;code&gt;supercollider&lt;/code&gt; simply looks like this:&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&quot;lang-supercollider\&quot;&gt;~osc  = (net: NetAddr(&amp;quot;localhost&amp;quot;, 57101));\n~compileHydra = {|c| Task({1.wait; ~osc.net.sendMsg(\\compile, c.canon.canon.size);}).play}; // the Task is used for delaying compilation for some reason I can not remember\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h2 id=\&quot;sending-canonic-data-to-hydra\&quot;&gt;Sending canonic data to hydra&lt;/h2&gt;\n&lt;p&gt;The &lt;code&gt;SuperCollider&lt;/code&gt; or rather, the &lt;code&gt;FluentCan&lt;/code&gt; code for sending each voices data looks like this:&lt;/p&gt;\n&lt;p&gt;First we define some helper functions:&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&quot;lang-supercollider\&quot;&gt;// Merge two Event objects.\n~merge = {|a, b| merge(a, b, { |a, b| b ? a })};\n\n// Calculate the tranposition for the visual parameters corresponding to each voice\n~transpf = {|fns, vals, event| fns.wrapAt(event.voiceIndex).(vals.wrapAt(event.eventIndex))};\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;Creating a FluentCan model with the osc connection&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&quot;lang-supercollider\&quot;&gt;~osc  = (net: NetAddr(&amp;quot;localhost&amp;quot;, 57101));\nm = FluentCan(osc: ~osc);\n~compileHydra = {|c| Task({1.wait; ~osc.net.sendMsg(\\compile, c.canon.canon.size);}).play};\n\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;Creating a canon:&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&quot;lang-supercollider\&quot;&gt;(\n    c = m.def(\\1)\n    .notes([60, 62,63]]) // do, re, mi\n  .period(3) // the notes sequences lasts 3 seconds before repeating\n\n  // these next two lines define the voices ratios and transpositions\n  .tempos([1, 2]) // the second voice is twice as fast as the other\n    .transps([0, 7]) // the second voice is transposed a fifth above\n    .play;\n\n  ~compileHydra.(c); // ~compileHydra receives the canon so that it can calculate the number of voices of the canon before sending the osc message\n)\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;Calculating the visual data and sending it on every sound event.\nFor the osc message we send an &lt;code&gt;Event&lt;/code&gt; object which is the most similar data structure to a JavaScript &lt;code&gt;Object&lt;/code&gt;.\nTo do that merge the original data of the &lt;code&gt;Event&lt;/code&gt; with the visual/hydra related data produced below&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&quot;lang-supercollider\&quot;&gt;(\nc.canon.player.onEvent({|ev|\n  // do something else, like producing sound...\n\n  // To send osc dat we call.\n    CanPlayer.makeOSC(\n    ~merge.(ev,\n        (\n            r: ~transpf.([_*1], [2], ev),\n            g: ~transpf.([_*1], [0], ev),\n            b: ~transpf.([_*0.2], [1], ev),\n            scale: ~transpf.([_*1], [1], ev),\n            noise: ~transpf.([_*0], [0], ev),\n            shape: ~transpf.([_*1], [2], ev),\n            repeat: ~transpf.([_+0], [1], ev),\n            x: ~transpf.([_*0], [0], ev),\n            xd: ~transpf.([_*0], [0], ev),\n            y: ~transpf.([_*0], [0], ev),\n            yd: ~transpf.([_*0], [0], ev),\n\n        )\n    )).(); // Note here the function call. `CanPlayer.makeOSC` returns a function which upon being called sends the osc message.\n})\n)\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;And thats it!&lt;/p&gt;\n&quot;}" data-reactid=".0.0.1.0.0.0.0"><p><em>La hora del live coder</em> is performance that explores possible strategies for visualizing temporal canons using <a href="https://github.com/nanc-in-a-can/fluent-can">FluentCan</a> and <a href="https://hydra.ojack.xyz/">hydra</a>. Additionally <code>Eikosanies</code> were used as the music&#39;s tuning system. The following is a tutorial for anyone interested in these techniques.</p>
<p>Personally, the most interesting thing about performance is in the communication between <code>supercollider</code> and <code>hydra</code>, since it is possible to control and even compile the <code>hydra</code> code from <code>supercollider</code>.</p>
<p>The second most interesting thing is that using <code>FluentCan</code> in conjunction with <code>hydra</code> (in this case) one can create graphical temporal canons, which is something I have not yet seen anywhere else.</p>
<p>The code repository and this tutorial can be found here: <a href="https://github.com/diegovdc/la-hora-del-live-coder">https://github.com/diegovdc/la-hora-del-live-coder</a></p>
<h2 id="how-to-compile-hydra-code-from-supercollider">How to compile hydra code from supercollider</h2>
<p>Please note that although this technique is used for compiling visual canons in <code>hydra</code>, it can be adapted to any situation where the control of what and how gets compiled by <code>hydra</code> should be defined by an external program.</p>
<p><strong>En Hydra</strong>:</p>
<p>The most basic (althought) trivial implementation looks like this (see below for a non trivial implementation)</p>
<pre><code class="lang-js">// `main` is a function that gets compiled every time there is a `compile` osc event
main = (oscPayload) =&gt; shape(oscPayload[0]).out();

// each time a /compile message is sent, then the main function is compiled...
msg.on(&quot;/compile&quot;, (oscPayload) =&gt; {
  main(oscPayload);
});
</code></pre>
<p>This implementation is trivial because we don&#39;t need to recompile <code>hydra</code> to pass a new value to the <code>shape</code> function. We could simply do this and save a lot of CPU cycles:</p>
<pre><code class="lang-js">shape(() =&gt; numberOfSides).out();

msg.on(&quot;/changeSides&quot;, (oscPayload) =&gt; {
  numberOfSides = oscPayload[0];
});
</code></pre>
<p>In the performance, however, <code>FluentCan</code> would produce canons with a different number of voices each time, so I wanted to automatically change in <code>hydra</code> the number of <code>shapes</code> that were produce to match the number of voices of the canon.</p>
<p>So I did the following.</p>
<p>First a layering function was need. If we want three layers (or voices) at a given time, then we want the layer function to be able to do something like this (but dynamically):</p>
<pre><code class="lang-js">shape().diff(shape()).diff(shape());
</code></pre>
<p>Using the JS library Ramda layer looks simply like this.</p>
<pre><code class="lang-js">layer = R.invoker(1, &quot;diff&quot;);
</code></pre>
<p>But <code>layer</code> could also be written like this in vanilla js:</p>
<pre><code class="lang-js">layer = (newLayer, accumulatedLayers) =&gt; accumulatedLayers.diff(newLayer);
</code></pre>
<p>An example use of layer is this:</p>
<pre><code class="lang-js">layer1 = layer(shape(2), shape(1)); //shape(1).diff(shape(2))
layer2 = layer(shape(3), layer1); // shape(1).diff(shape(2)).diff(shape(3))
</code></pre>
<p>But we want to create more interesting layers so this next function (<code>makeLayer</code>) is in charge of creating each layer (i.e. each <code>shape()</code>). It receives the data from a single voice (actually just the key) to create each of the shapes individually.</p>
<p>The <code>voices</code> object holds all the the different voices data (see below); and this stateful object will be used to access the current voice values on every iteration of the <code>hydra</code> graphics loop.</p>
<pre><code class="lang-js">// this version returns a colored shape, but it can be as complex as desired
makeLayer = (voice) =&gt;
  solid(
    () =&gt; voices[voice].r || 0,
    () =&gt; voices[voice].g || 0,
    () =&gt; voices[voice].b || 0
  ).mask(shape(() =&gt; voices[voice].shape || 3));
</code></pre>
<p>Next we define the <code>main</code> function which gets recompiled via osc.</p>
<p>Here <code>R.reduce</code> is used to iterate by the number of voices and <em>accumulate</em> our layers into a single signal. (Using js native <code>.reduce</code> or even <code>for loop</code> are good also alternatives).</p>
<p>So if there are 2 voices one would get something like:</p>
<pre><code class="lang-js">shape(1).diff(shape(2));
</code></pre>
<p>And with 3 voices something like:</p>
<pre><code class="lang-js">shape(1).diff(shape(2)).diff(shape(3));
</code></pre>
<p>However for our function to work we need a <em>base</em> layer. Something neutral, like <code>solid(0,0,0)</code>, works well. So we are actually going to get something like this:</p>
<pre><code class="lang-js">solid(0, 0, 0).diff(shape(1)).diff(shape(2)).diff(shape(3));
</code></pre>
<p>And so on... All generated automatically.</p>
<p>One would just need to substitute <code>shape</code> by whatever the output of makeLayer is.</p>
<pre><code class="lang-js">main = (voices) =&gt;
  R.reduce(
    (acc, voice) =&gt; layer(makeLayer(voice), acc), // voice is just a key in the voices object, i.e. `&quot;v1&quot;`, or `&quot;v2&quot;`
    solid(0, 0, 0), // this is the initial or base layer
    Object.keys(voices)
  ).out(); // we call .out on the accumulated layers
</code></pre>
<p>The content of the <code>voices</code> object is defined separately, so that when a voice&#39;s parameter is updated (on every sound event), the object changes but the <code>hydra</code> code need not be recompiled.</p>
<p>This object looks like this:</p>
<pre><code class="lang-js">{
  v1: {
    voiceIndex: 1,
    r: 0.5,
    g: 1,
    b: 0,
    // more params
  },
  v2: {
    voiceIndex: 2,
    r: 0,
    g: 0.1,
    b: 0.7
    // more params
  },
  // more voices
}
</code></pre>
<p>To update the voices object we use a message called <code>/canosc</code>.</p>
<pre><code class="lang-js">msg.on(&quot;/canosc&quot;, (msg_) =&gt; {
  // don&#39;t mind this next line too much, it just parses the osc message into an object like: {voiceIndex: 1, r: 0.5, g: 1, b: 0, ...otherParams}
  var msg__ = R.fromPairs(R.splitEvery(2, msg_));

  // the parsed voice is assigned to the voices object which the looks like this:
  // {v1: {r:0.5, ...otherParams}, v2: {...params}, ...}
  voices[&quot;v&quot; + msg__.voiceIndex] = msg__;
});
</code></pre>
<p>Resources in the actual code: <a href="https://github.com/diegovdc/la-hora-del-live-coder/blob/master/index.js#L14-L23">https://github.com/diegovdc/la-hora-del-live-coder/blob/master/index.js#L14-L23</a> y <a href="https://github.com/diegovdc/la-hora-del-live-coder/blob/master/index.js#L41-L51">https://github.com/diegovdc/la-hora-del-live-coder/blob/master/index.js#L41-L51</a></p>
<p>For compiling <code>hydra</code> the <code>supercollider</code> simply looks like this:</p>
<pre><code class="lang-supercollider">~osc  = (net: NetAddr(&quot;localhost&quot;, 57101));
~compileHydra = {|c| Task({1.wait; ~osc.net.sendMsg(\compile, c.canon.canon.size);}).play}; // the Task is used for delaying compilation for some reason I can not remember
</code></pre>
<h2 id="sending-canonic-data-to-hydra">Sending canonic data to hydra</h2>
<p>The <code>SuperCollider</code> or rather, the <code>FluentCan</code> code for sending each voices data looks like this:</p>
<p>First we define some helper functions:</p>
<pre><code class="lang-supercollider">// Merge two Event objects.
~merge = {|a, b| merge(a, b, { |a, b| b ? a })};

// Calculate the tranposition for the visual parameters corresponding to each voice
~transpf = {|fns, vals, event| fns.wrapAt(event.voiceIndex).(vals.wrapAt(event.eventIndex))};
</code></pre>
<p>Creating a FluentCan model with the osc connection</p>
<pre><code class="lang-supercollider">~osc  = (net: NetAddr(&quot;localhost&quot;, 57101));
m = FluentCan(osc: ~osc);
~compileHydra = {|c| Task({1.wait; ~osc.net.sendMsg(\compile, c.canon.canon.size);}).play};

</code></pre>
<p>Creating a canon:</p>
<pre><code class="lang-supercollider">(
    c = m.def(\1)
    .notes([60, 62,63]]) // do, re, mi
  .period(3) // the notes sequences lasts 3 seconds before repeating

  // these next two lines define the voices ratios and transpositions
  .tempos([1, 2]) // the second voice is twice as fast as the other
    .transps([0, 7]) // the second voice is transposed a fifth above
    .play;

  ~compileHydra.(c); // ~compileHydra receives the canon so that it can calculate the number of voices of the canon before sending the osc message
)
</code></pre>
<p>Calculating the visual data and sending it on every sound event.
For the osc message we send an <code>Event</code> object which is the most similar data structure to a JavaScript <code>Object</code>.
To do that merge the original data of the <code>Event</code> with the visual/hydra related data produced below</p>
<pre><code class="lang-supercollider">(
c.canon.player.onEvent({|ev|
  // do something else, like producing sound...

  // To send osc dat we call.
    CanPlayer.makeOSC(
    ~merge.(ev,
        (
            r: ~transpf.([_*1], [2], ev),
            g: ~transpf.([_*1], [0], ev),
            b: ~transpf.([_*0.2], [1], ev),
            scale: ~transpf.([_*1], [1], ev),
            noise: ~transpf.([_*0], [0], ev),
            shape: ~transpf.([_*1], [2], ev),
            repeat: ~transpf.([_+0], [1], ev),
            x: ~transpf.([_*0], [0], ev),
            xd: ~transpf.([_*0], [0], ev),
            y: ~transpf.([_*0], [0], ev),
            yd: ~transpf.([_*0], [0], ev),

        )
    )).(); // Note here the function call. `CanPlayer.makeOSC` returns a function which upon being called sends the osc message.
})
)
</code></pre>
<p>And thats it!</p>
</div></div></div></div></div></div></div></div><script src="/browser-main.js" type="text/javascript"></script><script src="https://www.youtube.com/iframe_api" type="text/javascript"></script></body></html>